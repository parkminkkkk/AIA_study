import numpy as np
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense
import tensorflow as tf
tf.random.set_seed(337)   #초기 가중치 고정 

#1. 데이터 
x = np.array([1,2,3,4,5])
y = np.array([1,2,3,4,5])

#2. 모델 
model = Sequential()
model.add(Dense(2, input_dim =1))
# numpy=array([[ 0.5376226 , -0.7160384 , -0.19092572]] : 초기 weight 임의의 값 // [0., 0., 0.] : bias의 초기값 // 'dense/kernel:0' : kernel(layer상의 커널) = weight 
model.add(Dense(1))

print(model.weights)
########################################################
model.trainable = False   # ★★★   /// 디폴트 : True

# model.trainable = False를 설정하면 해당 변수의 trainable 속성이 변경되어 해당 변수에 대한 역전파가 비활성화
# 따라서 해당 변수는 훈련 중에 업데이트되지 않음 
########################################################

model.summary()

#3. 컴파일, 훈련
model.compile(loss='mse', optimizer = 'adam')
model.fit(x,y,batch_size = 1, epochs=10)

y_predict = model.predict(x)
print(y_predict)

# False
# 5/5 [==============================] - 0s 750us/step - loss: 33.8580 : 로스 고정됨 = 가중치 갱신 안되고있다는 뜻 
# [[-0.7544218]
#  [-1.5088435]
#  [-2.2632656]
#  [-3.017687 ]
#  [-3.7721088]]


################################################################################################################
#최적의 weight를 가지고 다시 훈련을 시키고 싶을때 
#딥러닝의 경우, seed고정해도 틀어지는 경우 발생하므로=> 가중치 가져다가 사용하고, 훈련을 시키지 않는 것 
#남이 만든 좋은 모델을 재학습시킬때, 훈련을 다시 시켜야하는 이유가 있는가? =>> 따로 훈련 시키지 x (훈련 시키는 것이 오히려 성능 안좋을 수 있음)
#즉, 입력과 출력만 shape맞춰주고, 나머지는 똑같이 사용함...

##############전이학습, 사전학습, pre-training모델#################### 
#model.trainable = False을 사용하는 이유는 모델의 학습 가능한 가중치와 편향을 동결하는 것
#이 설정은 모델을 학습하는 동안 특정 레이어 또는 변수의 가중치 업데이트를 막는 데 사용
# 전이학습이란 이미 충분한 데이터와 여러 연구와 실험으로 만들어진 모델을 학습한 가중치를 가지고와 우리 모델에 맞게 재보정해서 사용하는 것
'''
1.사전 훈련된 모델 사용: 
 이미 대규모 데이터셋에서 사전 훈련된 가중치를 가진 모델을 사용하는 경우, 
 이러한 가중치를 동결하여 모델의 일부 또는 전체를 수정하지 않고 유지할 수 있습니다. 
 이렇게 하면 훈련 가능한 가중치 수가 줄어들어 연산 속도를 향상시킬 수 있습니다.

2.특정 레이어 고정: 
 모델의 특정 레이어를 고정하여 이전 레이어의 가중치만 업데이트되도록 할 수 있습니다. 
 예를 들어, 특정 레이어를 사전 훈련된 모델에서 가져와서 고정한 후, 
 나머지 레이어를 새로운 데이터셋에 맞게 학습할 수 있습니다. 이는 전이 학습(transfer learning)과 관련이 있습니다.

3. 학습을 중지하고 추론만 필요한 경우: 
모델이 학습을 완료한 후, 새로운 데이터에 대한 추론만 필요한 경우에는 가중치를 동결하여 추가 학습을 방지할 수 있습니다.

'''