#######################################################################################
ppt office2013
제출 양식 : 이름_개인프로젝트_프로젝트명.ppt
#우측 상단에 페이지 명시하기#

# #프로젝트 
# -이거, 저거, 요고 해봤는데 제일 좋은 모델이 이거여서 선택해보았다. (과정 필수)
#  (pt하나에 3가지 기술 썼다는 내용을 보여주기 좋음)
# -아키텍처, 구조, 
# =소스 필수(핵심기술)반드시!!
# -어떤 모델을 만들겠다. 
# -논문 : 구현했다x 나의 방식으로 아이디어를 넣어서 평가를 했다**
# -고도화 : 이런 식으로 하니까 더 좋은 결과가 나왔다 (명시!)

# #개인과제 
# 1. 아이디어 (어떤 데이터로 어떤 것을 만들 것인지, 아웃풋 명시)
# 2. 데이터 있어야함 
# 3. 타임테이블(일별로 4/5,6,7,8,9,10) 
# 4. pt(3~5장) : 이런데이터로 이런거 만들것이다/ 5분내외(6,7일목~금) 
# 5. 최종 : 11일(수) 최종 : end발표 (10~15분내외)
######################################################################################

1. 프로젝트 목적  
-스팸/비스팸 분류
-메일 청소 (깔끔한 메일함)


2. 내가 이용한 데이터 셋 -> 어떻게 쓸지 설명 / 어떤 데이터로 어떤 것을 만들 것인지(아웃풋 명시)
-어떤 식으로 구성할지 (train,test- split) / (train:비스팸, test:스팸)
-predict : 내가 명시. 

3. 사용예정 API (Model, Tonken)
*TfidfVectorizer
*CountVectorizer
count_vec = CountVectorizer(tokenizer=mytokenizer)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
*M1. lr = LogisticRegression()
*M2. scv= LinearSVC()

4. 타임테이블 
######################################################################################
<1차피드백>
#다른 주제 추가-날씨 : 
#한글 보강 - 한글 데이터 추가 :
#데이터 합쳐도 됨 : 근데 한글이냐 영어냐 구분이 되어야함 
#한글/ 영어data_set : 두개로 하거나 

<2차피드백>
#한글메일 만들기 - (번역은 조작임) - 메일함 뒤져,,,,
#keras 이진모델 만들어서 비교하기 
#(API) - Logistic/ SVC 등등.. 


<최종발표 ppt>
#PPT - 출처명시
#가독성 좋은 데이터 형태
#모델 아키텍처 : 입체적/모델구성
#summary랑 동일하도록 
#아키텍처, summary(총param) : 명시하기 
#최종결과 
 - 평가지표 명시 (신뢰도 높이기)
 - 시각화***(그래프)/ 동영상 또는 이미지로 아웃풋 명시하기 
#타임테이블 : 구체적으로
######################################################################################

'''
 'CountVectorizer'는 단순히 문서에서 각 단어의 발생을 세고 이를 단어 수의 행렬로 나타냅니다. 
예를 들어 "The cat in the hat", "The cat sat on the mat", "The dog ate the cat's food"의 세 가지 문서가 있는 경우 CountVectorizer는 다음과 같은 행렬을 생성합니다.
 반면 TfidfVectorizer는 문서에서 각 단어의 발생을 계산할 뿐만 아니라 모든 문서에서 전체 빈도로 각 단어에 가중치를 부여합니다. 
이것은 빈도-역 문서 빈도(tf-idf)라는 용어를 사용하여 수행됩니다. 이 공식은 문서에 자주 등장하지만 다른 문서에는 거의 나타나지 않는 단어에 높은 점수를 할당하고 그 반대의 경우도 마찬가지입니다. 
이렇게 하면 각 문서에서 가장 중요한 단어를 식별하는 데 도움이 됩니다. 예를 들어 동일한 세 문서의 tf-idf 값은 다음과 같습니다.

#CountVectorizer는 불용어("the", "and", "a"와 같이 많은 의미를 지니지 않는 일반적인 단어)를 제거하고 형태소 분석(단어를 어근 형태로 줄임) 및 텍스트(소문자로 변환).
#전반적으로 CountVectorizer는 구조화되지 않은 텍스트 데이터를 기계 학습 모델에 사용할 수 있는 형식으로 변환하는 데 유용한 도구

#TfidfVectorizer :텍스트 문서에서 각 단어의 중요성을 고려하는 텍스트 특징 추출 기술

요약하면 'CountVectorizer'는 단순히 각 단어의 발생 횟수를 세지만 
'TfidfVectorizer'는 문서 전체의 빈도를 기준으로 단어의 가중치를 지정하여 각 문서에서 가장 중요한 단어를 식별할 수 있습니다. 
어느 것을 사용할지는 특정 작업 및 데이터 세트에 따라 다르지만 일반적으로 'TfidfVectorizer'는 많은 NLP 응용 프로그램에서 더 강력한 것으로 간주됩니다.

'''
#분류 작업에 널리 사용#
'RandomForestClassifier'는 학습 데이터의 하위 집합에 여러 의사 결정 트리 모델을 맞춘 다음 결과를 결합하여 예측하는 앙상블 학습 방법입니다. 
의사 결정 트리는 데이터의 서로 다른 하위 집합에 대해 학습되며 각 트리에는 각 분할에서 고려되는 기능의 임의 하위 집합이 있습니다. 
그러면 'RandomForestClassifier'의 출력은 개별 트리의 예측된 클래스의 모드입니다. 
이 접근 방식은 여러 의사 결정 트리의 장점을 결합하여 과적합을 줄이고 정확도를 높이는 데 도움이 됩니다.

반면 'GradientBoostingClassifier'는 일련의 결정 트리를 데이터에 맞추는 또 다른 앙상블 학습 방법입니다. 
RandomForestClassifier와 달리 GradientBoostingClassifier의 결정 트리는 순차적으로 학습되며 각 후속 트리는 이전 트리에서 발생한 오류를 수정하려고 시도합니다. 
즉, 이전 트리에서 만든 예측을 개선하는 데 중점을 둡니다. 그러면 'GradientBoostingClassifier'의 출력은 개별 트리의 예측 값의 합입니다. 
이 접근 방식은 특히 복잡한 데이터 세트를 처리할 때 RandomForestClassifier보다 훨씬 더 나은 정확도로 이어질 수 있습니다.

'RandomForestClassifier'는 일반적으로 더 빠르고 조정하기 쉬운 
반면, 'GradientBoostingClassifier'는 복잡한 데이터 세트에 더 나은 정확도를 제공하는 경향이 있지만 계산 비용이 더 많이 들고 조정하기 어려울 수 있습니다.
'''
트리 구축 프로세스: 'RandomForestClassifier'는 여러 결정 트리를 독립적으로 구축합니다.
여기서 각 트리는 기능 및 학습 예제의 임의 하위 집합을 기반으로 구성됩니다. 
반면에 'GradientBoostingClassifier'는 각 트리가 이전 트리의 잔여 오류를 맞추려고 시도하는 결정 트리를 순차적으로 구축합니다.

편향-분산 트레이드오프: 'RandomForestClassifier'는 분산이 높은 여러 의사 결정 트리를 구축하고 출력을 평균화하여
 모델의 전체 분산을 줄여 과적합을 줄이도록 설계되었습니다. 
반면 'GradientBoostingClassifier'는 이전 트리의 실수를 수정하도록 훈련된 일련의 결정 트리를 구축하여 편향을 줄이도록 설계되어
 편향과 분산이 낮은 모델로 이어질 수 있습니다.
 '''


1. 한글데이터 
2. 한글데이터 전처리 
3. 모델 비교 
4. 그래프 찍어보기&비교 -> 한글데이터 비율 맞추기 
5. ppt만들기 
