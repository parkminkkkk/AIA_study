# path = 
# filenamelist = ['게룡', '공주'.,,]

# for i in file : 
#     a[i] = i + '.csv'
#     '계룡.csv'
#     aaa[i] = read_csv(path + '계룡.csv')

# import os  #한번에 떙겨오는 방법 
####################################

 2일 분량의 PM2.5 / AWS 데이터(test set)와 과거 기간의 PM2.5 / AWS 데이터 (train set)을 활용하여 3일 분량의 지역별 시간당 PM2.5 값을 예측합니다.

2. PM2.5 예측에 AWS값이 반드시 사용되어야 합니다. AWS 값을 사용하지 않은 모델은 무효처리됩니다.

3. 앙상블 규정 (설명 보충) 

모든 관측소에 대하여 같은 모델로 예측을 수행해야 하며
복수 모델의 추론 결과를 평균/가중합/투표하여 답안을 생성하는 형태 등의 결과적 앙상블을 허용하지 않습니다. 
다만, 추론 중간 과정에서 대상 요소별로 별도의 모델을 사용하고 추론된 결과를 다시 별도의 모델에 입력하여 결과를 만들어내는 경우(예: 기온 예측 모델, 습도 예측 모델을 만들고 예측된 기온과 습도를 이용하여 PM2.5를 예측하는 모델 등)는 하나의 모델이 여러 단계의 입력을 받아 결과를 생성하는 것으로 보아 허용됩니다. 대신 이 경우 추론 수행 시에는 최초 입력으로부터 최종 결과 생성까지의 과정에 인위적인 개입이 없이 seamless한 pipeline으로 연결될 수 있어야 합니다.  
핵심은 앙상블 모델 금지, 그리고 관측소별로 별도의 모델(해당 관측소 외에는 사용 불가능한 전용 모델)을 만드는 것이 아니라 global한 모델을 만드는 것을 목표로 해야 한다는 것입니다.
4. train set을 test set 예측에 사용할 수 있습니다. 하지만 test set을 모델 학습에 사용할 수 없습니다.

'''
**시계열데이터 -날짜 자르기(년,월,일,시,분,초)** 
-주식의 경우 : 년,월,일,시,분,초,토,일,공휴일...

#방법1. 
-(컬럼 소량(pm) 사용/x,y데이터 만들어서 사용)
-y값 명확, PM2.5데이터별로 날짜별로 자르기, x는 2일치(48개) y는 3일치(72개) : 2일치 데이터로 3일치 P.M예측
-train데이터 y값 결측치(imputer) => 이후 여기있는 데이터 사용 (48개 다음엔 72개야, 반복하면서 예측)
-(35000,48)(35000,72) 만들기 / 날짜데이터까지 잘라서 사용할 경우 (35000,4,48)(35000,72) 
-LSTM/ Conv1D모델 사용 
-다차원 xgboost돌릴 수 없음 (머신러닝모델은 3차원 안먹힘 ) => (35000,4*48)(35000,72)해서 shape만 맞춰서 돌릴 수는 있음 

#방법2.
-라벨인코더 => 지역(수치화로 변경)
-연도별로 비교 => 코로나 시점 전/후로 총 미세먼지 양의 차이가 날 수 있음(1,2,3,4)중에서 하나가 커질 수 있음.. -> linear형태
-일시 중요 => 서쪽에서 바람불때(겨울) // 남쪽에서 바람불때(여름)  : 12,1,2월에 미세먼지 더 많을 확률 높음 : 월을 데이터로 사용가능, 그러나 일은 데이터로 사용하기에 명확하지 xx
-시간데이터 => 낮>밤 // 아침<점심 
-연도, 일시, 지역, pm(y) => 일시는 월과 일로 잘라줌 - 컬럼 4개로 늘어남 / 지역데이터는 라벨인코더 
-즉, ㅇㅇㅇㅇ일때 y값이야! 를 맞추는 모델 : 35000번해서 가중치 생성 => 이후, test데이터로 확인 

#AWS : 30개 지점 있음/ 최근접이웃 - 특정 지점이 가까이 있다면 3개중 1개 선택해서 데이터 뒤에 붙이면 됨.. (성능 더 안좋아질 수도 있음..왜냐하면 가중치 가장 높은 것은 PM2.5이므로,,)
#따라서, PM2.5가 가중되는 것... 잘 찾기... 
'''
